{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping for Data job in CO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the link to the search query\n",
    "\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO\n",
    "\n",
    "As you can see at the bottom of the page there are link to series of pages related to this search.\n",
    "If you click on second page, search url changes to\n",
    "\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO&start=10\n",
    "\n",
    "If you click on 3rd then url changes to\n",
    "\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO&start=20\n",
    "\n",
    "Hence to go to more pages we can format search string(**change start=??** part) for **requests.get in a loop**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape 10 pages and build a pandas DataFrame containing following information\n",
    "\n",
    "   + job title, name of the company, location, summary of job description\n",
    "   + Indicator columns(with value True/False) about keywords Python, SQL, AWS, Machine learning, Deep Learning, Text Mining, STATA, SAS, Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data+analyst OR data+scientist\n",
    "mainpage=\"https://www.indeed.com\"\n",
    "detail_page_list,job_title_list=[],[]\n",
    "for job in [\"analyst\",\"scientist\"]:\n",
    "    for i in range(0,10):\n",
    "        page=i*10\n",
    "        search_string=f\"https://www.indeed.com/jobs?q=data+{job}&l=CO&start={page}\"\n",
    "        response=rq.get(search_string) \n",
    "        ## raise an error if the connection fails\n",
    "        if response.status_code !=200:\n",
    "            raise ValueError(f'The connection for page {search_string} failed.')\n",
    "        soup= bsp(response.text, 'lxml')\n",
    "        ## get hyperlink for each job \n",
    "        title_link=soup.find_all('a',{\"data-tn-element\":\"jobTitle\"})  \n",
    "        for hyperlink in title_link:\n",
    "            ## get job title\n",
    "            job_title_list+=[hyperlink.get_text().strip(\"\\n\")] \n",
    "            ## for each hyperlink, save the link \n",
    "            detail_link=mainpage+hyperlink['href']\n",
    "            detail_page_list+=[detail_link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=11 []\n",
      "i=13 []\n",
      "i=16 []\n",
      "i=58 []\n",
      "i=78 []\n",
      "i=88 []\n",
      "i=114 []\n",
      "i=160 []\n",
      "i=163 []\n",
      "i=173 []\n",
      "i=187 []\n",
      "i=204 []\n",
      "i=224 []\n",
      "i=225 []\n",
      "i=261 []\n",
      "i=263 []\n",
      "i=294 []\n",
      "i=322 []\n",
      "i=330 []\n",
      "i=333 []\n",
      "i=339 []\n"
     ]
    }
   ],
   "source": [
    "company_name_list,company_location_list,detail_description_list=[],[],[]\n",
    "## enter each detailed page for more job information\n",
    "## also records page with no details\n",
    "no_content=set()\n",
    "for i in range(0,len(detail_page_list)):\n",
    "    individual_link=detail_page_list[i]\n",
    "    response_detail=rq.get(individual_link)\n",
    "    if response_detail.status_code !=200:\n",
    "        raise ValueError(f'The connection for page {individual_link} failed.')\n",
    "    soup_detail=bsp(response_detail.text,'lxml')\n",
    "    company_info=soup_detail.find_all('div',{'class':'icl-u-lg-mr--sm icl-u-xs-mr--xs'}) \n",
    "    ## job links contain advertisement for Indeed Prime which would need to be excluded\n",
    "    if company_info:\n",
    "        ## get the companyname and location\n",
    "        company_name_list+=[company_info[0].get_text().strip(\"\\n\")]\n",
    "        company_location_list+=[company_info[1].next_sibling.get_text().strip(\"\\n\")]  \n",
    "        ## search for key words in decription\n",
    "        job_description=str(soup_detail.find_all(\"div\",{\"class\":\"jobsearch-JobComponent-description icl-u-xs-mt--md\"}))\n",
    "        detail_description_list+=[job_description]\n",
    "    else:\n",
    "        print(f'i={i}',company_info)\n",
    "        no_content.add(i)\n",
    "        company_name_list+=[None]\n",
    "        company_location_list+=[None]\n",
    "        detail_description_list+=[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "## there are times that Python mistakenly missed some information other than those indeed prime ads\n",
    "## need to repeately run the following to fill those holes untill all the Nones were due to indeed prime page\n",
    "print(no_content)\n",
    "filled=set()\n",
    "for i in no_content:\n",
    "    individual_link=detail_page_list[i]\n",
    "    response_detail=rq.get(individual_link)\n",
    "    if response_detail.status_code !=200:\n",
    "        raise ValueError(f'The connection for page {individual_link} failed.')\n",
    "    soup_detail=bsp(response_detail.text,'lxml')\n",
    "    company_info=soup_detail.find_all('div',{'class':'icl-u-lg-mr--sm icl-u-xs-mr--xs'}) \n",
    "    ## job links contain advertisement for Indeed Prime which would need to be excluded\n",
    "    if len(company_info)>0:\n",
    "        ## get the companyname and location\n",
    "        company_name_list[i]=[company_info[0].get_text()]\n",
    "        company_location_list[i]=[company_info[1].next_sibling.get_text()]  \n",
    "        ## search for key words in decription\n",
    "        job_description=str(soup_detail.find_all(\"div\",{\"class\":\"jobsearch-JobComponent-description icl-u-xs-mt--md\"}))\n",
    "        detail_description_list[i]=[job_description]\n",
    "        filled.add(i)  \n",
    "print(filled)\n",
    "no_content={i for i in no_content if i not in filled}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## verify above\n",
    "for i in no_content:\n",
    "    print(summary_description_list[i])\n",
    "## all the links below are ads for Indeed Prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Key_Python,Key_SQL,Key_AWS,Key_Machine_Learning,Key_Deep_Learning,Key_Text_Mining,\\\n",
    "Key_SAS,Key_Tableau,Key_Stata=[],[],[],[],[],[],[],[],[]\n",
    "## search for key words\n",
    "for i in range(0,len(detail_description_list)):\n",
    "    if i not in no_content:\n",
    "        job_description=str(detail_description_list[i])\n",
    "        # Python\n",
    "        if re.search('Python', job_description, re.IGNORECASE):\n",
    "            Key_Python+=[True]\n",
    "        else:\n",
    "            Key_Python+=[False]\n",
    "        # SQL\n",
    "        if re.search('SQL', job_description):\n",
    "            Key_SQL+=[True]\n",
    "        else:\n",
    "            Key_SQL+=[False]\n",
    "        # AWS\n",
    "        if re.search('AWS', job_description):\n",
    "            Key_AWS+=[True]\n",
    "        else:\n",
    "            Key_AWS+=[False]   \n",
    "        # Machine Learning\n",
    "        if re.search('Machine Learning', job_description, re.IGNORECASE):\n",
    "            Key_Machine_Learning+=[True]\n",
    "        else:\n",
    "            Key_Machine_Learning+=[False]\n",
    "        # Deep Learning\n",
    "        if re.search('Deep Learning', job_description, re.IGNORECASE):\n",
    "            Key_Deep_Learning+=[True]\n",
    "        else:\n",
    "            Key_Deep_Learning+=[False]\n",
    "        # Text Mining\n",
    "        if re.search('Text Mining', job_description, re.IGNORECASE):\n",
    "            Key_Text_Mining+=[True]\n",
    "        else:\n",
    "            Key_Text_Mining+=[False]\n",
    "        # SAS\n",
    "        if re.search('SAS', job_description):\n",
    "            Key_SAS+=[True]\n",
    "        else:\n",
    "            Key_SAS+=[False]\n",
    "        # Tableau\n",
    "        if re.search('Tableau', job_description, re.IGNORECASE):\n",
    "            Key_Tableau+=[True]\n",
    "        else:\n",
    "            Key_Tableau+=[False]\n",
    "        # Stata\n",
    "        if re.search('Stata', job_description, re.IGNORECASE):\n",
    "            Key_Stata+=[True]\n",
    "        else:\n",
    "            Key_Stata+=[False]\n",
    "    else:\n",
    "        Key_Python+=[None]\n",
    "        Key_SQL+=[None]\n",
    "        Key_AWS+=[None]\n",
    "        Key_Machine_Learning+=[None]\n",
    "        Key_Deep_Learning+=[None]\n",
    "        Key_Text_Mining+=[None]\n",
    "        Key_SAS+=[None]\n",
    "        Key_Tableau+=[None]\n",
    "        Key_Stata+=[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title                 object\n",
      "Company               object\n",
      "Location              object\n",
      "SummaryDescription    object\n",
      "Python                  bool\n",
      "SQL                     bool\n",
      "AWS                     bool\n",
      "Machine_Learning        bool\n",
      "Deep_Learning           bool\n",
      "Text_Mining             bool\n",
      "SAS                     bool\n",
      "Tableau                 bool\n",
      "STATA                   bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## create data frame\n",
    "data={\"Title\":job_title_list,\"Company\":company_name_list,\\\n",
    "      \"Location\":company_location_list,\"SummaryDescription\":detail_description_list,\\\n",
    "      \"Python\":Key_Python,\"SQL\":Key_SQL,\"AWS\":Key_AWS,\\\n",
    "        \"Machine_Learning\":Key_Machine_Learning,\\\n",
    "     \"Deep_Learning\":Key_Deep_Learning,\"Text_Mining\":Key_Text_Mining,\\\n",
    "\"SAS\":Key_SAS,\"Tableau\":Key_Tableau,\\\n",
    "     \"STATA\":Key_Stata}\n",
    "job_indeed_df=pd.DataFrame.from_dict(data)\n",
    "print(job_indeed_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City with the most job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Centennial', 'ColoradoSprings', 'Boulder', 'GreenwoodVillage', 'LoneTree', 'Lafayette', 'Aurora', 'Denver', 'Broomfield', 'Littleton', 'Loveland', 'Englewood', 'Colorado', 'GrandJunction', 'Louisville', 'Henderson', 'Superior', 'Westminster', 'Lakewood', 'Longmont', 'Golden', 'HighlandsRanch'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>SummaryDescription</th>\n",
       "      <th>Python</th>\n",
       "      <th>SQL</th>\n",
       "      <th>AWS</th>\n",
       "      <th>Machine_Learning</th>\n",
       "      <th>Deep_Learning</th>\n",
       "      <th>Text_Mining</th>\n",
       "      <th>...</th>\n",
       "      <th>Colorado</th>\n",
       "      <th>GrandJunction</th>\n",
       "      <th>Louisville</th>\n",
       "      <th>Henderson</th>\n",
       "      <th>Superior</th>\n",
       "      <th>Westminster</th>\n",
       "      <th>Lakewood</th>\n",
       "      <th>Longmont</th>\n",
       "      <th>Golden</th>\n",
       "      <th>HighlandsRanch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Private</td>\n",
       "      <td>Aurora, CO 80011</td>\n",
       "      <td>[&lt;div class=\"jobsearch-JobComponent-descriptio...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sales Analyst</td>\n",
       "      <td>Science Interactive Group</td>\n",
       "      <td>Englewood, CO</td>\n",
       "      <td>[&lt;div class=\"jobsearch-JobComponent-descriptio...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Intern Analyst</td>\n",
       "      <td>Real Capital Solutions</td>\n",
       "      <td>Louisville, CO 80027</td>\n",
       "      <td>[&lt;div class=\"jobsearch-JobComponent-descriptio...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020 Summer Intern: Data Analyst</td>\n",
       "      <td>SPECTRUM</td>\n",
       "      <td>Greenwood Village, CO 80121</td>\n",
       "      <td>[&lt;div class=\"jobsearch-JobComponent-descriptio...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Director of Data Analytics</td>\n",
       "      <td>Suited Connector</td>\n",
       "      <td>Englewood, CO 80112</td>\n",
       "      <td>[&lt;div class=\"jobsearch-JobComponent-descriptio...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title                    Company  \\\n",
       "0                      Data Analyst                    Private   \n",
       "1                     Sales Analyst  Science Interactive Group   \n",
       "2                    Intern Analyst     Real Capital Solutions   \n",
       "3  2020 Summer Intern: Data Analyst                   SPECTRUM   \n",
       "4        Director of Data Analytics           Suited Connector   \n",
       "\n",
       "                      Location  \\\n",
       "0             Aurora, CO 80011   \n",
       "1                Englewood, CO   \n",
       "2         Louisville, CO 80027   \n",
       "3  Greenwood Village, CO 80121   \n",
       "4          Englewood, CO 80112   \n",
       "\n",
       "                                  SummaryDescription Python    SQL    AWS  \\\n",
       "0  [<div class=\"jobsearch-JobComponent-descriptio...  False  False  False   \n",
       "1  [<div class=\"jobsearch-JobComponent-descriptio...  False  False  False   \n",
       "2  [<div class=\"jobsearch-JobComponent-descriptio...  False  False  False   \n",
       "3  [<div class=\"jobsearch-JobComponent-descriptio...   True   True   True   \n",
       "4  [<div class=\"jobsearch-JobComponent-descriptio...  False  False  False   \n",
       "\n",
       "  Machine_Learning Deep_Learning Text_Mining  ... Colorado GrandJunction  \\\n",
       "0            False         False       False  ...    False         False   \n",
       "1            False         False       False  ...    False         False   \n",
       "2            False         False       False  ...    False         False   \n",
       "3            False         False       False  ...    False         False   \n",
       "4            False         False       False  ...    False         False   \n",
       "\n",
       "  Louisville  Henderson  Superior  Westminster  Lakewood  Longmont  Golden  \\\n",
       "0      False      False     False        False     False     False   False   \n",
       "1      False      False     False        False     False     False   False   \n",
       "2       True      False     False        False     False     False   False   \n",
       "3      False      False     False        False     False     False   False   \n",
       "4      False      False     False        False     False     False   False   \n",
       "\n",
       "   HighlandsRanch  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load data\n",
    "df=job_indeed_df.astype(\"str\").drop_duplicates()\n",
    "## get unique cities/towns\n",
    "unique_location=set(df.Location.str.replace(\"[^a-zA-Z]|CO\",\"\"))\n",
    "print(unique_location)\n",
    "for l in unique_location:\n",
    "    df[l] = df.Location.map(lambda x: l in re.sub(\"[^a-zA-Z]|CO\",\"\",x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Denver        88\n",
       "Boulder       18\n",
       "Englewood     15\n",
       "Broomfield    14\n",
       "Aurora        11\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## count={i:0 for i in unique_location}\n",
    "## for i in df.Location.str.replace(\"[^a-zA-Z]|CO\",\"\"):\n",
    "##     if i in count:\n",
    "##         count[i]+=1\n",
    "## count\n",
    "## ------------------------------------------------------\n",
    "## or directly using \n",
    "## df.sum()[unique_location].sort_values(ascending=False)\n",
    "df.sum()[unique_location].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 3 most demanding skills(like Python, AWS, SQL ...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python              119\n",
       "SQL                 113\n",
       "Machine_Learning     75\n",
       "Tableau              49\n",
       "AWS                  36\n",
       "SAS                  31\n",
       "Deep_Learning        25\n",
       "STATA                 5\n",
       "Text_Mining           3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert str Ture&False to Boolean\n",
    "df_skills=df[ ['Python','SQL','AWS','Machine_Learning','Deep_Learning','Text_Mining','SAS','Tableau','STATA'] ].replace({'True': True, 'False': False})\n",
    "## sort and show Top 3 most demanding skills\n",
    "## df_skills.sum().sort_values(ascending=False)\n",
    "df_skills.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
